#!/bin/bash
#SBATCH -J mlm                           # Job name
#SBATCH -o logs/mlm/%j.out               # output file (%j expands to jobID)
#SBATCH -e logs/mlm/%j.err               # error log file (%j expands to jobID)
#SBATCH -N 1                                 # Total number of nodes requested
#SBATCH -n 4                                 # Total number of cores requested
#SBATCH --get-user-env                       # retrieve the users login environment
#SBATCH --mem=64g                            # server memory requested (per node)
#SBATCH -t 10:00:00                           # Time limit (hh:mm:ss)
#SBATCH --partition=gpu,desa                     # Request partition
#SBATCH --gres=gpu:a6000:1                # Type/number of GPUs needed

dataset=$1
shift
dataset_config=$1
shift
config=$1
shift
balance=$1
shift
seed=$1

if [ -z "$1" ]; then
  echo "Usage: $0 <dataset> <dataset_config> <config> <balance> <seed> <args>"
  exit 1
fi

shift

CMD="python experiments/nlp/run_mlm_no_trainer.py \
--dataset_name $dataset \
--dataset_config_name $dataset_config \
--config_name $config \
--tokenizer_name $config \
--with_tracking \
--seed $seed \
--balance_type $balance \
--checkpointing_steps epoch \
--output_dir checkpoints/$config/$dataset/$dataset_config/$balance/$seed \
$*"

echo "$CMD"
eval "$CMD"
